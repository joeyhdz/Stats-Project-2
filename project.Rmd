---
title: "STAT Project #2"
author: 'Joey Hernandez | Krithika Kondakindi | Santiago Guti√©rrez<br><br><br>'
always_allow_html: TRUE
output: 
  html_document: 
    code_folding: hide
    toc: yes
    toc_depth: 2
    number_sections: no
    theme: spacelab
    highlight: tango
  github_document: default
---
<style>
.title {
  text-align: center;
  font-weight: bold;
}
.author {
  text-align: center;
}
h1 {
  text-align: center;
  font-size: 36px;
}
</style>

<br>

<hr>
# **Packages & Data**
<hr>

<br>
<br>

## Load Initial Packages For Cleaning
<hr>
```{r, message=F, warning=F, fig.align='center'}
#install.packages('janitor')
#install.packages('aplore3')

library(aplore3) # for our dataset
library(tidyverse) # tools for viz/cleaning/etc
library(janitor) # tools for cleaning
library(visdat) # visualize our missing data
```

## Data Inspection
<hr>

Takeaways: 
  
  - Looking at the data we see that some of the weight values (in KG) are very low. Assuming the low weight belongs to individuals who are older - maybe bed ridden - and have instances of sarcopenia, this is plausible... but, it's also good to keep this in mind moving forward. 
  
  - Raterisk: This is a completely subjective topic. It may be interesting to see, but not expected to provide much insight. 
  
  - Duplicate data: There is instances of duplicated data in the site_id, phy_id. This makes sense since many sites will occur with repeating metrics and many physicians will also occur with those same metrics. 
  
  - Smoke has a very small sample of "Yes" (35).
  
```{r, message=F, warning=F, fig.align='center'}
# adding dataset into df call.
df <- glow_bonemed  

# looking at our data from afar 
#glimpse(df) # a lot of categorical vars (factor encoding)

# for a look at a brief data description uncomment lines below:
#?glow_bonemed 
#?glow500


# check for duplicated data
# get_dupes(df, sub_id) # no duplicated data here which is what we'd like to see. 
# get_dupes(df, site_id) # makes sense that we would have duplicated study sites.
# get_dupes(df, phy_id) # makes sense that we would have duplicated physician id codes.

# check for missing values
#vis_miss(df) # great! No missing values. 

# visualizing the summary of our data. 
summary(df)
```

<br>

<hr>
# **EDA**
<hr>

<br>

## EDA (Categorical)
<hr>
Step One: Visualize what the Yes/No's look like in terms of fractures. 
  
  - The plot below will show us without yet incorporating predictors, what is the percentages of yes/no that we are seeing in the data. 
  
  - Findings are that it's not a very balanced split. 75% of the data have NO for fracture. When we make predictive probabilities how will this influence the result? will we find that they are around this value with some higher/lower? *(potential sanity check to our results later)*
  
  - Additional Note... Unbalanced data is OK.. this should maybe be revisited in our threshold.
```{r, message=F, warning=F, fig.align='center'}
library(ggplot2)
library(gridExtra)

c <- df %>% # allows us to gather table of y/n fracture, the cnt, and percent. 
  group_by(fracture) %>% 
  summarise(cnt = n()) %>% 
  mutate(perc=round(cnt/sum(cnt),4))

#c # shows the result of the above

# bar plot visual of the above. 
p<- ggplot(c, aes(x = fracture, y = perc, colour = fracture)) + 
  geom_bar(aes(fill = fracture), show.legend = F, stat = 'identity') +
  ylab('Proportion of Fracture') + xlab("Fracture") +
  geom_text(aes(label = paste0(perc *100, "%")), vjust = 2, size = 5, color = 'black')

```

Fracture - Menopause Before Age 45

  - When and individual did not have menopause before age 45 (pre-menopause) the chances of having a fracture are much higher even though there is only a 25% of having a fracture.
  
  - If you are in the no pre-menopause group, it is approx 80% chance that you have a fracture. it decreases as for those who did have pre-menopause. 
  
```{r, message=F, warning=F, fig.align='center'}

c1 <- df %>% 
  group_by(fracture, premeno) %>% 
  summarise(cnt=n()) %>% 
  mutate(perc=round(cnt/sum(cnt),4))%>% 
  arrange(desc(perc))

#c1

p1<- ggplot(c1[c(2,3),], aes(x = reorder(premeno, -perc), y = perc, colour = premeno))+
  geom_bar(aes(fill = premeno), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') +
  xlab('Menopause before age 45')+
  geom_text(aes(label = paste0(perc *100, "%")), vjust = 2, size = 5, color = 'black')

```

Fracture - Momfrac (Mother Had Hip Fracture)

  - When an individual did not have a mother that had a hip fracture the chances of having a fracture are much higher (80.8%) even though there is only a 25% of having a fracture. 

  - If an individual is in the "Mother did not have a hip fracture" group, there is an 80.8% chance that you will have a fracture. This decreases for those who did have a mother with a hip fracture.  

```{r, message=F, warning=F, fig.align='center'}
c2 <- df %>% 
  group_by(fracture, momfrac) %>%
  summarise(cnt=n()) %>% 
  mutate(perc = round(cnt/sum(cnt),4)) %>%
  arrange(desc(perc))

#c2

p2<- ggplot(c2[c(2,3),], aes(x = reorder(momfrac, -perc), y = perc, color = momfrac)) + 
  geom_bar(aes(fill = momfrac), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') + 
  xlab("Mother had Hip fracture") + 
  geom_text(aes(label = paste0(perc * 100, "%")), vjust = 2, size = 5, color = "black")

```

Fracture - Smoke (Current / Former Smoker)

  - When an individual falls in the category of former/current smoker the chances of having a fracture are much higher (94.4%) even though there is only a 25% of having a fracture.

```{r, message=F, warning=F, fig.align='center'}
c3 <- df %>% 
  group_by(fracture, smoke) %>%
  summarise(cnt=n()) %>% 
  mutate(perc = round(cnt/sum(cnt),4)) %>%
  arrange(desc(perc))

#c3

p3<- ggplot(c3[c(1,4),], aes(x = reorder(smoke, -perc), y = perc, color = smoke)) + 
  geom_bar(aes(fill = smoke), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') + 
  xlab("Former/Current Smoker") + 
  geom_text(aes(label = paste0(perc * 100, "%")), vjust = 1, size = 5, color = "black")

```

Fracture - Raterisk (Self-Reported Risk of Fracture)

  - Classified by the following groups...less than others of same age, same as others of same age, greater than others of same age).

  - An issue with this is that it's a very subjective measure. WHY are they rating this? is it based off non-inclusive criteria that the physician provided? is it based on their own physical comparison with peers? is it simply low-self esteem/ high self esteem?  I would imagine that from a predictive model stand point this is NOT something that should be included. 
  
```{r, message=F, warning=F, fig.align='center'}
c4 <- df %>% 
  group_by(fracture, raterisk) %>%
  summarise(cnt=n()) %>% 
  mutate(perc = round(cnt/sum(cnt),4)) %>%
  arrange(desc(perc))

#c4

p4<- ggplot(c4[c(1,2,6),], aes(x = reorder(raterisk, -perc), y = perc, color = raterisk)) + 
  geom_bar(aes(fill = raterisk), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') + 
  xlab("Self-Risk-Score") + 
  geom_text(aes(label = paste0(perc * 100, "%")), vjust = 2, size = 4, color = "black")

```

Fracture - Bonemed (Bone Medications at Enrollment)

  - When an individual is in the category of No medication at enrollment the chances of having a fracture are much higher (63.2%) even though there is only a 25% of having a fracture.
  
```{r, message=F, warning=F, fig.align='center'}
c5 <- df %>% 
  group_by(fracture, bonemed) %>%
  summarise(cnt=n()) %>% 
  mutate(perc = round(cnt/sum(cnt),4)) %>%
  arrange(desc(perc))

#c5

p5<- ggplot(c5[c(2,3),], aes(x = reorder(bonemed, -perc), y = perc, color = bonemed)) + 
  geom_bar(aes(fill = bonemed), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') + 
  xlab("Medication at Enrollment") + 
  geom_text(aes(label = paste0(perc * 100, "%")), vjust = 2, size = 5, color = "black")

```

Fracture - Bonemed_fu (Bone Medications at Follow-up)

  - When an individual is in the category of No medication at Follow-up the chances of having a fracture are higher (57.6% versus 42.4%) even though there is only a 25% of having a fracture.

```{r, message=F, warning=F, fig.align='center'}
c6 <- df %>% 
  group_by(fracture, bonemed_fu) %>%
  summarise(cnt=n()) %>% 
  mutate(perc = round(cnt/sum(cnt),4)) %>%
  arrange(desc(perc))

#c6

p6<-ggplot(c6[c(2,3),], aes(x = reorder(bonemed_fu, -perc), y = perc, color = bonemed_fu)) + 
  geom_bar(aes(fill = bonemed_fu), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') + 
  xlab("Medication at Follow-up") + 
  geom_text(aes(label = paste0(perc * 100, "%")), vjust = 2, size = 5, color = "black")

```

Fracture - Bonetreat (Bone Medications Both at Enrollment & Follow-up)

  - When an individual is in the category of No treatment at both enrollment and follow-up the chances of having a fracture are much higher (68% versus 32%) even though there is only a 25% of having a fracture.

```{r, message=F, warning=F, fig.align='center'}
c7 <- df %>% 
  group_by(fracture, bonetreat) %>%
  summarise(cnt=n()) %>% 
  mutate(perc = round(cnt/sum(cnt),4)) %>%
  arrange(desc(perc))

#c7

p7<-ggplot(c7[c(2,3),], aes(x = reorder(bonetreat, -perc), y = perc, color = bonetreat)) + 
  geom_bar(aes(fill = bonetreat), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') + 
  xlab("Treatment: Enrollment & Follow-up") + 
  geom_text(aes(label = paste0(perc * 100, "%")), vjust = 2, size = 5, color = "black")

```


Fracture - Arms Needed to Stand From a Chair
  
  - Very balanced between the two groups. 
  
  - When an individual is in the category of needing assistance to stand the chances of having a fracture are higher( 50.4% versus 49.6%) even though there is only a 25% of having a fracture.
```{r, message=F, warning=F, fig.align='center'}

c8 <- df %>% 
  group_by(fracture, armassist) %>% 
  summarise(cnt=n()) %>% 
  mutate(perc=round(cnt/sum(cnt),4))%>% 
  arrange(desc(perc))

#c8

p8<- ggplot(c8[c(2,3),], aes(x = reorder(armassist, -perc), y = perc, colour = armassist))+
  geom_bar(aes(fill = armassist), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') +
  xlab('Assistance to Stand')+
  geom_text(aes(label = paste0(perc *100, "%")), vjust = 2, size = 5, color = 'black')

```


Fracture - Priorfrac (History of Prior Fracture)

  - When an individual is in the category of NOT having had a prior fracture the chances of having a fracture are higher (58.4% versus 41.6%) even though there is only a 25% of having a fracture.

```{r, message=F, warning=F, fig.align='center'}
c9 <- df %>% 
  group_by(fracture, priorfrac) %>%
  summarise(cnt=n()) %>% 
  mutate(perc = round(cnt/sum(cnt),4)) %>%
  arrange(desc(perc))

#c9

p9<-ggplot(c9[c(2,3),], aes(x = reorder(priorfrac, -perc), y = perc, color = priorfrac)) + 
  geom_bar(aes(fill = priorfrac), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') + 
  xlab("Prior Fracture") + 
  geom_text(aes(label = paste0(perc * 100, "%")), vjust = 2, size = 5, color = "black")

```


Fracture - BMI (Body Mass Index)
  - Some domain expertise here: there is evidence that individuals who are heavier tend to have less instances of osteoporosis, and hip/bone fractures. this is unsurprising to see here and is a good depiction of prior research. 

  - Including this variable into the model should be something that is significant based on the trend we see, although the instance of "underweight" is interesting and may require some investigation. 
  
  - When an individual is in the category "Healthy Weight" the chances of having a fracture are highest (35.2%), followed by Overweight (32.8%), followed by Obesity (30.4%), and lastly Underweight (1.6%).
```{r, message=F, warning=F, fig.align='center'}
# transforming numeric into categorical using widely accepted BMI categories
df$bmi.cat <- ifelse(df$bmi < 18.5, "Underweight", 
                              ifelse(df$bmi < 25, "Healthy weight",
                                     ifelse(df$bmi < 30, "Overweight", "Obesity")))

c10 <- df %>% 
  group_by(fracture, bmi.cat) %>% 
  summarise(cnt=n()) %>% 
  mutate(perc=round(cnt/sum(cnt),4))%>% 
  arrange(desc(perc))

#c10

p10<- ggplot(c10[c(2,3,5,8),], aes(x = reorder(bmi.cat, -perc), y = perc, colour = bmi.cat))+
  geom_bar(aes(fill = bmi.cat), show.legend = F, stat = 'identity') + 
  ylab('Proportion of Fracture') +
  xlab('BMI Categories')+
  geom_text(aes(label = paste0(perc *100, "%")), vjust = 1, size = 4, color = 'black')

```

<br>

## Visualizing Categorical Plots
<hr>

```{r, message=F, warning=F, fig.align='center'}

grid.arrange(p,p1,p2,p3,p4,
             heights = c(1,1))

grid.arrange(p5,p6,p7,p8,p9,p10,
             heights= c(1,1),
             widths = c(1,1,1.6))

```

<br>
<br>

## Visualizing "Important" Categorical Predictors
<hr>

```{r, message=F, warning=F, fig.align='center'}
grid.arrange(p,p1,p2,p3,p4,
             heights = c(1,1))

grid.arrange(p5,p7,p10,
             heights = c(1,1),
             widths = c(1,1,1.6))
```


## EDA (Numerical)
<hr>

We would like to look at some of the relationships for the numerical categories in our data. Before we can do this it is important for us to create a numerical category for fracture so that we can create our LOESS plot. 
  
  - Note to smooth the curve out some, we can use span values (such as 1.25), either way this is artificial humps and bumps, try not to pay attention to the overall movements and look instead at the trend/association of how the data moves with increasing/decreasing values. 
  
  - Note for complex models We can add categorical values to this (interactions). Also, facet wrapping will allow us to view them separate. 
  
```{r, message=F, warning=F, fig.align='center'}
# numerical form of fracture
df$fracture.num <- ifelse(df$fracture == "Yes",1,0) # Yes = 1 | No = 0
```

LOESS phy_id:

  - No significance here.

```{r, message=F, warning=F, fig.align='center'}
lp <- df %>% ggplot(aes(x = phy_id, y = fracture.num)) + 
  geom_point() + ggtitle("LOESS: Phy_ID")+
  geom_smooth(method = "loess", size = 1) + ylim(-.2, 1.2)
```

LOESS site_id:

  - No significance here.
```{r, message=F, warning=F, fig.align='center'}
lp1<- df %>% ggplot(aes(x = site_id, y = fracture.num)) + 
  geom_point() + 
  geom_smooth(method = "loess", size = 1) + ylim(-.2, 1.2)+ ggtitle("LOESS: Site_id")
```

LOESS WEIGHT:

  - No significance here.
```{r, message=F, warning=F, fig.align='center'}
lp2<- df %>% ggplot(aes(x = weight, y = fracture.num)) + 
  geom_point() + 
  geom_smooth(method = "loess", size = 1) + ylim(-.2, 1.2)+ ggtitle("LOESS: Weight")

```

LOESS AGE:

  - As age increases the is an increase in the chance of a fracture.
```{r, message=F, warning=F, fig.align='center'}
lp3<- df %>% ggplot(aes(x = age, y = fracture.num)) +
  geom_point() +
  geom_smooth(method = "loess", size = 1) + ylim(-.2, 1.2)+ ggtitle("LOESS: Age")

```

LOESS HEIGHT:

  - As Height decreases there is a decrease in the chance of a fracture.
```{r, message=F, warning=F, fig.align='center'}
lp4<- df %>% ggplot(aes(x = height, y = fracture.num)) + 
  geom_point()+
  geom_smooth(method = "loess", size = 1) + ylim(-.2, 1.2)+ ggtitle("LOESS: Height")
```

LOESS fracscore (Fracture Risk Score (Composite Risk Score)):

  - As the score increases there is an increase in the chance of a fracture.
```{r, message=F, warning=F, fig.align='center'}
lp5<- df %>% ggplot(aes(x = fracscore, y = fracture.num)) + 
  geom_point()+
  geom_smooth(method = "loess", size = 1) + ylim(-.2, 1.2)+ ggtitle("LOESS: fracscore")

```

```{r, message=F, warning=F, fig.align='center'}
lp6 <- df %>% ggplot(aes(x = bmi, fracture.num)) + 
  geom_point()+
  geom_smooth(method = 'loess', size = 1) + ylim(-.2,1.2) + ggtitle("Loess: BMI")

```

<br>

## Numerical Plots
<hr>
```{r, message=F, warning=F, fig.align='center'}
grid.arrange(lp,lp1,lp2,lp3,lp4,lp5,lp6,
             heights = c(1,1))
```

<br>
<br>

## Test/Validation Split
<hr>
```{r, message=F, warning=F, fig.align='center'}
library(caret)
set.seed(12)
trainIndex <- createDataPartition(df$fracture, p= .8, list = F) # p = proportion of data in train

training <- df[trainIndex,]
test <- df[-trainIndex,]

# sanity check
#nrow(training)
#nrow(test)

```

<br>
<br>

<hr>
# **Objective 1**
<hr>

<br>

## Fit Logistic Regression Model
<hr>

**Note:** The coefficients are LOG-ODDS and not ratios. To obtain ratios we must exp(coef).
```{r, message=F, warning=F, fig.align='center'}
library(ResourceSelection)
library(car)

# fitting an additive multiple logistic regression model
simple <- glm(fracture ~ smoke + armassist + momfrac + premeno + bmi + height + age + bonemed + bonetreat + bonemed_fu, data = training, family ="binomial")

# looking at coefficients
(simple.summary<- summary(simple))

# looking for Multicollinearity
(simple.vif <- vif(simple))

# AIC metric can help us compare against models with interactions later to determine if the interactions are important or not. 
(simple.AIC <- AIC(simple))

# Hosmer-Lemeshow test
(simple.hlt <- hoslem.test(simple$y, fitted(simple)))
```

<br>
<br>

**Simple Model Coefficients and CI's**
```{r, message=F, warning=F, fig.align='center'}
# coefficient output for log. reg. model:
(simple.coef<- coef(simple)) # normal coefficient output
(simple.exp<- exp(coef(simple))) # exp coefficient

# confidence intervals
(simple.ci<- exp(confint(simple, level = .95))) # confidence interval @ .05 significance

```

<br>
<br>

**Reducing the Model Predictors:**

  - Some reduction is due to insignificance.
  - Some predictors are kept however due to real world applicability. 

```{r, message=F, warning=F, fig.align='center'}
red.model <- glm(fracture~ priorfrac+momfrac+age+bonetreat+bonemed_fu+bmi,
                 data = training,
                 family ="binomial")

# summary of coef. 
summary(red.model)

# AIC metric can help us compare against models with interactions later to determine if the interactions are important or not. 
(red.aic <- AIC(red.model))

# looking for Multicollinearity
(red.vif <- vif(red.model)) # we do have a high VIF in bonetreat.

# Hosmer-Lemeshow test
(red.hlt <- hoslem.test(red.model$y, fitted(red.model)))

```

<br>
<br>

**Reduced Model Coefficients and CI's:**
```{r, message=F, warning=F, fig.align='center'}
# coefficient output for log. reg. model:
(red.coef<- coef(red.model)) # normal coefficient output
(red.exp<- exp(coef(red.model))) # exp coefficient

# confidence intervals
(red.ci<- exp(confint(red.model, level = .95))) # confidence interval @ .05 significance

```

<br>
<br>

## Coefficient Interpretations & Significance
<hr>

Based on our results, we interpret each variable as follows:

<br>

  - **Intercept:** The intercept represents the baseline odds of a patient experiencing a fracture when all other variables are equal to zero. The odds ratio is 0.0031, which means that the baseline odds of a patient experiencing a fracture are very low.

  - **PriorfracYes:** The odds ratio for priorfracYes is 2.4629, which means that patients who have a history of prior fracture are 2.4629 times more likely to experience a fracture than those who do not have a history of prior fracture. The 95% confidence interval for the odds ratio ranges from 1.4484 to 4.1798, which suggests that this variable has a statistically significant effect on the odds of experiencing a fracture.

  - **MomfracYes:** The odds ratio for momfracYes is 1.9252, which means that patients whose mother had a hip fracture are 1.9252 times more likely to experience a fracture than those whose mother did not have a hip fracture. The 95% confidence interval for the odds ratio ranges from 0.9860 to 3.6914, which suggests that there is some uncertainty in the effect of this variable on the odds of experiencing a fracture.

  - **Age:** The odds ratio for Age is 1.0422, which means that for every one-year increase in age, patients are 1.0422 times more likely to experience a fracture. The 95% confidence interval for the odds ratio ranges from 1.0125 to 1.0730, which suggests that this variable has a statistically significant effect on the odds of experiencing a fracture.

  - **BonetreatYes:** The odds ratio for bonetreatYes is 0.3461, which means that patients who were taking bone medications both at enrollment and follow-up are 0.3461 times less likely to experience a fracture than those who were not taking bone medications. The 95% confidence interval for the odds ratio ranges from 0.1201 to 0.9492, which suggests that this variable has a statistically significant effect on the odds of experiencing a fracture.

  - **Bonemed_fuYes:** The odds ratio for bonemed_fuYes is 5.9176, which means that patients who were taking bone medications at follow-up are 5.9176 times more likely to experience a fracture than those who were not taking bone medications. The 95% confidence interval for the odds ratio ranges from 2.2978 to 16.0797, which suggests that this variable has a statistically significant effect on the odds of experiencing a fracture.

  - **BMI:** The odds ratio for BMI is 1.0413, which means that for every one-unit increase in BMI, patients are 1.0413 times more likely to experience a fracture. The 95% confidence interval for the odds ratio ranges from 0.9972 to 1.0871, which suggests that there is some uncertainty in the effect of this variable on the odds of experiencing a fracture.

<br>
<br>

## Individual Effect Plots
<hr>


Because we are working with an additive model, plotting one by one is ok to do without losing much information. 

```{r, message=F, warning=F, fig.align='center'}
library(sjPlot)
library(sjmisc)
library(effects)

# effect plot
plot_model(red.model, type = "pred", terms = "priorfrac")
plot_model(red.model, type = "pred", terms = "momfrac")
plot_model(red.model, type = "pred", terms = "age")
plot_model(red.model, type = "pred",terms = "bmi")
plot_model(red.model, type = "pred", terms = "bonetreat")
plot_model(red.model, type = "pred", terms = "bonemed_fu")
# identifies all of the high-order terms in a model and returns a list of "eff" or "effpoly" objects.
all.effects <- allEffects(red.model)

# plots the effect plosts
plot(all.effects,multiline=T)

```

<br>

## Effect Plot Combos
<hr>

  
Provides an intuitive way to understand impact of each predictor on the outcome, while holding the other predictors constant. 
  
```{r, message=F, warning=F, fig.align='center'}

# effect plot
plot_model(red.model, type = "pred", terms = c("bonetreat","priorfrac"))
plot_model(red.model, type = "pred", terms = c("age","bonetreat"))
plot_model(red.model, type ="pred", terms = c("age","bonemed_fu"))
plot_model(red.model, type = "pred", terms = c("age","priorfrac"))  
plot_model(red.model, type = "pred", terms = c("bmi","bonetreat"))
plot_model(red.model, type = "pred", terms = c("bmi","priorfrac"))
plot_model(red.model, type = "pred", terms = c("momfrac","priorfrac")) 

```

<br>
<br>

## ROC Curve for Additive Models
<hr>

**Multiple Logistic Regression: "Simple" Model**
```{r, message=F, warning=F, fig.align='center'}
library(pROC)

# predicting probabilities on the testing data
simple.predprobs <- predict(simple,test, type = 'response')
#simple.predprobs

simple.roc <- roc(response = test$fracture,
                  predictor = simple.predprobs,
                  levels = c("No","Yes"))
  
plot(simple.roc, print.thres= "best", col = "red")
```

<br>
<br>

**CV Model ROC**
```{r, message=F, warning=F, fig.align='center'}
# parameters for train function
fitControl <- trainControl( method = "repeatedcv", number = 5, repeats = 1, classProbs = T, summaryFunction = mnLogLoss)

# set seed for reproduceability 
set.seed(12)

# training CARET mult. logi. regression model 
add.model <- train(fracture~ priorfrac+momfrac+age+bonetreat+bonemed_fu+bmi,
                 data = training,
                 trControl = fitControl,
                 method = "glm",
                 family = "binomial",
                 metric = "logLoss")

summary(add.model)

# make preds on the probabilty of each class in TRANING data
add.model.predprob <- predict(add.model,test, type = "prob")

# compute the ROC curve
add.model.roc <- roc(response = test$fracture, predictor = add.model.predprob$Yes, levels = c("Yes","No"))


# plot ROC curve
plot(add.model.roc, print.thres = "best", print.thres.best.method = "closest.topleft", col = "red")
# add legend to plot
legend("bottomright",
       legend = 'caret model',
       col = "red",
       lwd = 4, cex = 1, xpd = T, horiz = F)

# get coord (threshold)
coords <- coords(add.model.roc, "best", best.method = "closest.topleft", ret = "threshold")

# get optimal threshold
threshold <- coords[[1]] # currently this is 0.2472446

# make changes to threshold if desired
adj.threshold <- threshold + 0

# adjust the labeling by the desired threshold
pred_label <- as.factor(ifelse(add.model.predprob$Yes >= adj.threshold, "Yes","No"))

# print confusion matrix
confusionMatrix(pred_label, test$fracture)

```

<br>
<br>

<hr>
# **Objective 2**
<hr>

<br>

## Investigating Potential for Interactions
<hr>
```{r, message=F, warning=F, fig.align='center'}
# age | bmi.cat - potential interaction ? 
df %>% ggplot(aes(x = age, y = fracture.num, color = bmi.cat)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~bmi.cat)

# height | bmi.cat - potential interaction ? 
df %>% ggplot(aes(x = height, y = fracture.num, color = bmi.cat)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~bmi.cat)

# bmi | fracscore - potential interaction ?  
df %>% ggplot(aes(x = bmi, y = fracture.num, color = armassist)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~armassist)

# bmi | fracscore - potential interaction ?  
df %>% ggplot(aes(x = bmi, y = fracture.num, color = fracscore)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~fracscore)

# bmi | priorfrac - potential interaction ?  
df %>% ggplot(aes(x = bmi, y = fracture.num, color = priorfrac )) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~priorfrac)

# height | raterisk - potential interaction ?  
df %>% ggplot(aes(x = height, y = fracture.num, color = raterisk)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~raterisk)


# height | bonemed - potential interaction ?  
df %>% ggplot(aes(x = bmi, y = fracture.num, color = bonemed)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~bonemed)


# height | bonemed_fu - potential interaction ?  
df %>% ggplot(aes(x = bmi, y = fracture.num, color = bonemed_fu)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~bonemed_fu)

# height | bonetreat - potential interaction ?  
df %>% ggplot(aes(x = bmi, y = fracture.num, color = bonetreat)) +
  geom_point()+
  geom_smooth(method = "loess", size = 1, span = .75) +
  ylim(-.2, 1.2) + facet_wrap(~bonetreat)


```

<br>
<br>

## Complex Model 1
<hr>

```{r, message=F, warning=F, fig.align='center'}
complex1 <- glm(fracture ~ bonemed + bonetreat + bonemed_fu + bmi + bmi:bonemed + bmi:bonetreat + bmi:bonemed_fu,
                data = training,
                family = "binomial")

summary(complex1)
vif(complex1)
AIC(complex1)

# printing out all AIC metrics (note they are based on training data not test data)
cat("SimpleModel :", simple.AIC,
    "\nComplex Model 1:", AIC(complex1),
    "\nReduced Model:", red.aic)
```

<br>
<br>

## Complex Model 2
<hr>

```{r, message=F, warning=F, fig.align='center'}
# parameters for train function
fitControl <- trainControl( method = "repeatedcv", number = 5, repeats = 1, classProbs = T, summaryFunction = mnLogLoss)

# set seed for reproduceability 
set.seed(12)

# training CARET mult. logi. regression model 
complex2 <- train(fracture~ priorfrac+momfrac+age+bonetreat+bonemed_fu+bmi +bonemed_fu:age + momfrac:priorfrac,
                 data = training,
                 trControl = fitControl,
                 method = "glm",
                 family = "binomial",
                 metric = "logLoss")

summary(complex2)
```

<br>

  - Simple Model:       415.24
  - Reduced Model:      **408.50**
  - Complex Model 1:    413.71
  - Complex Model 2:    **408.44**
  - Complex Model 3:    TBD

As you can see from the summary results just above, complex model 2 produces the smallest AIC; however, it is only slightly lower than our original reduced model without interactions. Let's see if complex model 3 can produce an even lower AIC.

<br>
<br>

## Complex Model 3
<hr>

```{r, message=F, warning=F, fig.align='center'}
# parameters for train function
fitControl <- trainControl( method = "repeatedcv", number = 5, repeats = 1, classProbs = T, summaryFunction = mnLogLoss)

# set seed for reproduceability 
set.seed(12)

# training CARET mult. logi. regression model 
complex3 <- train(fracture ~ priorfrac + momfrac + age + bonemed + bonetreat + bonemed_fu + bmi + bmi:bonemed + bmi:bonetreat + bmi:bonemed_fu +bonemed_fu:age + momfrac:priorfrac,
                 data = training,
                 trControl = fitControl,
                 method = "glm",
                 family = "binomial",
                 metric = "logLoss")

summary(complex3)
```

<br>

  - Simple Model:       415.24
  - Reduced Model:      408.50
  - Complex Model 1:    413.71
  - Complex Model 2:    **408.44**
  - Complex Model 3:    **396.49**
  
As you can see from the summary results just above, complex model 3 produces the smallest AIC by a good margin. This model includes all the significant variables and all of the evident interactions. We recommend using Complex Model 3 for attempting to predict fractures. Next, we'll check the ROC curve and AUC metric for this model. Then, we'll compare these results with that of a QDA model, an LDA model, and a KNN model.

<br>

```{r, message=F, warning=F, fig.align='center'}
# predicting probabilities on the testing data
complex3.pred <- predict(complex3, test, type = "prob")

complex3.roc <- roc(response = test$fracture,
                  predictor = complex3.pred[,2],
                  levels = c("No","Yes"))
  
plot(complex3.roc, print.thres= "best", col = "red")
pROC::auc(complex3.roc)
```
<br>

A value of 0.5 would indicate that the classifier is performing no better than random guessing, so the given AUC value of 0.5728 indicates that the classifier is performing slightly better than random guessing, but its discriminating ability is still poor. In other words, the classifier is able to differentiate between positive and negative samples to some extent, but its predictions are not reliable enough to be useful in practice.

<br>
<br>

## LDA & QDA Models
<hr>

```{r, message=F, warning=F, fig.align='center'}
library(MASS)
library(pROC)

# Fit LDA model
lda_model <- lda(fracture ~ priorfrac + momfrac + age + bonemed + bonetreat + bonemed_fu + bmi + bmi:bonemed + bmi:bonetreat + bmi:bonemed_fu + bonemed_fu:age + momfrac:priorfrac, data = training)
lda_predict <- predict(lda_model, test, type = "prob")

# Fit QDA model
qda_model <- qda(fracture ~ priorfrac + momfrac + age + bonemed + bonetreat + bonemed_fu + bmi + bmi:bonemed + bmi:bonetreat + bmi:bonemed_fu + bonemed_fu:age + momfrac:priorfrac, data = training)
qda_predict <- predict(qda_model, test, type = "prob")

# Compute the confusion matrix
cmLDA <- confusionMatrix(lda_predict$class, test$fracture, positive = "Yes")
cmQDA <- confusionMatrix(qda_predict$class, test$fracture, positive = "Yes")

# Compute the ROC curve and AUC value
lda.roc <- roc(response = test$fracture,
               predictor = lda_predict$posterior[,2],
               levels = c("No","Yes"))
qda.roc <- roc(response = test$fracture,
               predictor = qda_predict$posterior[,2],
               levels = c("No","Yes"))

# Output the ROC curve and AUC value
plot(lda.roc, main = "LDA and QDA ROC Curves", print.thres= "best", col = "red")
lines(qda.roc, col = "blue")
legend("bottomright", legend = c("LDA", "QDA"), col = c("red", "blue"), lty = 1)

cmLDA
cmQDA

pROC::auc(lda.roc)
pROC::auc(qda.roc)
```

<br>

A value of 0.5 would indicate that the classifier is performing no better than random guessing, so the given AUC values of 0.5744 and 0.5707 suggest that the LDA & QDA models are performing slightly better than random guessing, but its discriminating ability is still poor. In other words, the classifier is able to differentiate between positive and negative samples to some extent, but its predictions are also not reliable enough to be useful in practice.

<br>
<br>

## KNN Model
<hr>

```{r, message=F, warning=F, fig.align='center'}
library(caret)
library(pROC)

# Split the data into training and test sets
set.seed(123)

# Fit the KNN model with k=7
knnModel <- train(fracture ~ priorfrac + momfrac + age + bonemed + bonetreat + bonemed_fu + bmi + bmi:bonemed + bmi:bonetreat + bmi:bonemed_fu + bonemed_fu:age + momfrac:priorfrac,
                  data = training,
                  method = "knn",
                  trControl = trainControl(method = "cv", number = 10))

knnPred <-predict(knnModel, test)


# Compute the confusion matrix
cmKNN <- confusionMatrix(knnPred, test$fracture, positive = "Yes")
cmKNN

# Make predictions on the test set
knnPredProb <- predict(knnModel, test, type="prob")

# Compute the ROC curve and AUC value
knn.roc <- roc(response = test$fracture,
               predictor = knnPredProb[,2],
               levels = c("No","Yes"))


# Output the ROC curve and AUC value
plot(knn.roc, main = "KNN ROC Curve", print.thres= "best", col = "red")
pROC::auc(knn.roc)
```

<br>
  
A value of 0.5 would indicate that the classifier is performing no better than random guessing, so the given AUC value of 0.5109 indicates that the classifier is performing slightly better than random guessing, but its discriminating ability is still poor. In other words, the classifier is able to differentiate between positive and negative samples to some extent, but its predictions are not reliable enough to be useful in practice.


<br>